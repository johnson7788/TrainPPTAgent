# ====================================================================
# 云端 LLM 与 向量嵌入 服务提供商的 API Key
#
# 为你准备使用的提供商配置 API Key。
# 这些密钥同时用于文本生成与嵌入模型。
# 参考 `backend/simpleOutline/create_model.py`（用于 LLM）
# 和 `backend/personaldb/embedding_utils.py`（用于嵌入）。
# ====================================================================

# Google Gemini 模型
# - LLM 提供商：google，例如：LLM_MODEL=gemini-1.5-pro-latest
GOOGLE_API_KEY=xxx

# OpenAI 模型
# - LLM 提供商：openai，例如：LLM_MODEL=gpt-4
OPENAI_API_KEY=xxx

# Anthropic Claude 模型
# - LLM 提供商：claude，例如：LLM_MODEL=claude-3-opus-20240229
CLAUDE_API_KEY=xxx

# DeepSeek 模型
# - LLM 提供商：deepseek，例如：LLM_MODEL=deepseek-chat
DEEPSEEK_API_KEY=xxx

# 阿里云 DashScope 模型（Qwen）
# - LLM 提供商：ali，例如：LLM_MODEL=qwen-turbo
# - 嵌入提供商：aliyun，例如：EMBEDDING_MODEL=text-embedding-v2
ALI_API_KEY=sk-xxx

# 豆包（火山引擎）模型
# - LLM 提供商：doubao，例如：LLM_MODEL=Doubao-pro-32k
# - 嵌入提供商：doubao，例如：EMBEDDING_MODEL=doubao-embedding
DOUBAO_API_KEY=xxx

# SiliconFlow 模型
# - LLM 提供商：silicon，例如：LLM_MODEL=<model_name>
SILICON_API_KEY=xxx

# ModelScope 模型
# - LLM 提供商：modelscope，例如：LLM_MODEL=<model_name>
MODELSCOPE_API_KEY=xxx


# ====================================================================
# 自托管 / 本地模型 配置
#
# 对 LLM 与 嵌入模型均适用。
# ====================================================================

# --- vLLM ---
# 用于 LLM：MODEL_PROVIDER=vllm, LLM_MODEL=<model_name>
VLLM_API_URL=http://127.0.0.1:8000/v1
VLLM_API_KEY=EMPTY
# 用于嵌入：EMBEDDING_PROVIDER=vllm, EMBEDDING_MODEL=<model_name>
VLLM_BASE_URL=http://127.0.0.1:8000/v1

# --- Ollama ---
# 用于 LLM：MODEL_PROVIDER=ollama, LLM_MODEL=<model_name>
OLLAMA_API_URL=http://127.0.0.1:11434/v1
OLLAMA_API_KEY=EMPTY
# 用于嵌入：EMBEDDING_PROVIDER=ollama, EMBEDDING_MODEL=<model_name>
OLLAMA_BASE_URL=http://127.0.0.1:11434

# --- Xinference（仅嵌入）---
# 用于嵌入：EMBEDDING_PROVIDER=xinference, EMBEDDING_MODEL=<model_name>
XINFERENCE_BASE_URL=http://127.0.0.1:9997/v1
XINFERENCE_API_KEY=EMPTY

# --- 通用本地 OpenAI 兼容服务（仅 LLM）---
# 用于 LLM：MODEL_PROVIDER=local, LLM_MODEL=<model_name>
# LOCAL_API_URL=http://localhost:6688
# LOCAL_API_KEY=EMPTY


# ====================================================================
# 应用中的模型选择
#
# 为不同任务选择要使用的模型。
# ====================================================================

# --- 大纲生成主模型 ---
# MODEL_PROVIDER：选择 LLM 提供商。
# 支持：google, claude, openai, deepseek, ali, silicon, modelscope, doubao, vllm, ollama, local
MODEL_PROVIDER=ali
LLM_MODEL=qwen-turbo

# --- 幻灯片内容生成（撰写与校对代理）---
# 你可以为撰写和校对代理选择不同的模型。
PPT_WRITER_PROVIDER=ali
PPT_WRITER_MODEL=qwen-turbo

PPT_CHECKER_PROVIDER=ali
PPT_CHECKER_MODEL=qwen-turbo


# ====================================================================
# 知识库向量嵌入模型选择
# ====================================================================

# --- 知识库向量嵌入 ---
# EMBEDDING_PROVIDER：aliyun、doubao、vllm、xinference、ollama
# EMBEDDING_MODEL：所选提供商的具体模型名。
# EMBEDDING_DIM：（可选）若模型支持，可指定期望的向量维度。

# Doubao 示例：
EMBEDDING_PROVIDER=doubao
EMBEDDING_MODEL=doubao-embedding-text-240715

# 阿里云示例：
# EMBEDDING_PROVIDER=aliyun
# EMBEDDING_MODEL=text-embedding-v2

# 本地 Ollama 模型示例：
# EMBEDDING_PROVIDER=ollama
# EMBEDDING_MODEL=mxbai-embed-large

# 如果使用 GPU，可启用 Mineru 自动下载模型。需要 mineru[core]>=2.0.6
# USE_MINERU=false


# ====================================================================
# 内部服务 URL 与其他设置
#（本地部署通常无需更改）
# ====================================================================

# 内部 API 端点
OUTLINE_API=http://127.0.0.1:10001
CONTENT_API=http://127.0.0.1:10011
PERSONAL_DB=http://127.0.0.1:9100

# 网络代理（可选）
# 若访问 API（如 OpenAI）需要代理，请取消注释。
# HTTP_PROXY=http://127.0.0.1:7890
# HTTPS_PROXY=http://127.0.0.1:7890

# 启用/禁用图表生成
# 若使用较小模型且其在图表数据生成方面表现欠佳，可设为 false。
USE_CHART=True
